{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a model\n",
    "In the following example, we save the obtained model after each 100 epochs. The model is saved in a file with name `./my_model.ckpt`. Also, we save the last model in another file with name `./my_model_final.ckpt`.<br>\n",
    "After construction, you can add additional commands to save the model.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Use CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "n_epochs = 500 #500\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# Create random input and output data\n",
    "inputs = np.random.randn(N, D_in)\n",
    "targets = np.random.randn(N, D_out)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(inputs, name=\"X\")\n",
    "y = tf.constant(targets, name=\"y\")\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = tf.Variable(np.random.randn(D_in, H),name=\"weight1\")\n",
    "w2 = tf.Variable(np.random.randn(H, D_out),name=\"weight2\")\n",
    "\n",
    "# Forward pass: compute predicted y\n",
    "h = tf.matmul(X, w1, name=\"layer1\")\n",
    "h_relu = tf.maximum(h, 0)\n",
    "y_pred = tf.matmul(h_relu, w2, name=\"layer2-predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "loss = tf.reduce_sum(tf.square(error),name=\"squared_error\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss) # optimizer.minimize(loss,var_list=[var for var in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss = 35152534.05807968\n",
      "Epoch 100 loss = 438.9809194458144\n",
      "Epoch 200 loss = 2.1308103854750726\n",
      "Epoch 300 loss = 0.016409163154095473\n",
      "Epoch 400 loss = 0.00014366194899308464\n",
      "Epoch 500 loss = 1.3276589461294605e-06\n"
     ]
    }
   ],
   "source": [
    "# Execution phase\n",
    "session_conf = tf.ConfigProto(device_count = {'CPU': 1})\n",
    "sess=tf.Session(config=session_conf)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver() # <-------------------- create a saver object\n",
    "\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs+1):\n",
    "    _,loss_ = sess.run([training_op,loss]) # evaluate both in just one graph\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch\", epoch, \"loss =\", loss_)\n",
    "        save_path = saver.save(sess, \"./my_model.ckpt\") \n",
    "        \n",
    "save_path=saver.save(sess, \"./my_model_final.ckpt\") # <-------------------- the last model\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run `save_path = saver.save(sess, \"./my_model.ckpt\")`, 3 files are created:\n",
    "- my_model.ckpt.data-00000-of-00001\n",
    "- my_model.ckpt.index\n",
    "- my_model.ckpt.meta: the saver also saves the graph structure itself in this file.\n",
    "\n",
    "`save_path` is an optional output contains the path.<br><br>\n",
    "In the above code, the saved model after each 100 epochs is **replaced** with a new one. You can save them seperately in different folders. see [here](https://github.com/ashkan-abbasi66/python-tricks/blob/master/README.md#tf-saveModel).<br>Another alternative is to use `global_step`:<br>\n",
    "`save_path = saver.save(sess, \"./my_model.ckpt\",global_step=epoch)`<br>\n",
    "This results in the following files (when `epoch=200`):\n",
    "- my_model.ckpt-200.data-00000-of-00001\n",
    "- my_model.ckpt-200.index\n",
    "- my_model.ckpt-200.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the latest checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the name of **the latest checkpoint** and the epoch number!<br>\n",
    "Run the following piece of code: (the only differences with the above code are 1) we used `global_step`, and 2) we do not save the last model as a seperate file (In the above code, the last model is `./my_model_final.ckpt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss = 35152534.05807968\n",
      "Epoch 100 loss = 438.9809194458144\n",
      "Epoch 200 loss = 2.1308103854750726\n",
      "Epoch 300 loss = 0.016409163154095473\n",
      "Epoch 400 loss = 0.00014366194899308464\n",
      "Epoch 500 loss = 1.3276589461294605e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Use CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "n_epochs = 500 #500\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# Create random input and output data\n",
    "inputs = np.random.randn(N, D_in)\n",
    "targets = np.random.randn(N, D_out)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(inputs, name=\"X\")\n",
    "y = tf.constant(targets, name=\"y\")\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = tf.Variable(np.random.randn(D_in, H),name=\"weight1\")\n",
    "w2 = tf.Variable(np.random.randn(H, D_out),name=\"weight2\")\n",
    "\n",
    "# Forward pass: compute predicted y\n",
    "h = tf.matmul(X, w1, name=\"layer1\")\n",
    "h_relu = tf.maximum(h, 0)\n",
    "y_pred = tf.matmul(h_relu, w2, name=\"layer2-predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "loss = tf.reduce_sum(tf.square(error),name=\"squared_error\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss) # optimizer.minimize(loss,var_list=[var for var in tf.trainable_variables()])\n",
    "\n",
    "# Execution phase\n",
    "session_conf = tf.ConfigProto(device_count = {'CPU': 1})\n",
    "sess=tf.Session(config=session_conf)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver() # <-------------------- create a saver object\n",
    "\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs+1):\n",
    "    _,loss_ = sess.run([training_op,loss]) # evaluate both in just one graph\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch\", epoch, \"loss =\", loss_)\n",
    "        save_path = saver.save(sess, \"./my_model.ckpt\",global_step=epoch) # <-------------------- every 100 epochs\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the latest check point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_model.ckpt-500\n",
      "['500']\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "model_path='./'\n",
    "ckpt = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt)\n",
    "ckpt_num = re.findall(r'(\\w*[0-9]+)\\w*', ckpt)\n",
    "print(ckpt_num)\n",
    "start_point = int(ckpt_num[0])\n",
    "print(start_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "<tf.Variable 'weight1:0' shape=(1000, 100) dtype=float64_ref>\n",
      "<tf.Variable 'weight2:0' shape=(100, 10) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables. ** important step **\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "w1 = tf.Variable(np.random.randn(D_in, H),name=\"weight1\")\n",
    "w2 = tf.Variable(np.random.randn(H, D_out),name=\"weight2\")\n",
    "\n",
    "# create a saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "session_conf=tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess=tf.Session(config=session_conf)\n",
    "\n",
    "# Restore variables from disk.\n",
    "saver.restore(sess,\"./my_model_final.ckpt\")\n",
    "\n",
    "print(w1)\n",
    "print(w2)\n",
    "# print(loss) # name 'loss' is not defined\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore variables with a new name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restore `w1` with a **different name**, such as `t1`. Note that the name of `w1` is `weight1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "<tf.Variable 't1:0' shape=(1000, 100) dtype=float64_ref>\n",
      "<tf.Variable 'weight2:0' shape=(100, 10) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables. ** important step **\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "t1 = tf.Variable(np.random.randn(D_in, H),name=\"t1\")\n",
    "w2 = tf.Variable(np.random.randn(H, D_out),name=\"weight2\")\n",
    "\n",
    "# create a saver object\n",
    "saver = tf.train.Saver(var_list={'weight1':t1})\n",
    "\n",
    "session_conf=tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess=tf.Session(config=session_conf)\n",
    "\n",
    "# Restore variables from disk.\n",
    "saver.restore(sess,\"./my_model_final.ckpt\")\n",
    "\n",
    "print(t1)\n",
    "print(w2)\n",
    "# print(w1) # name 'w1' is not defined\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
