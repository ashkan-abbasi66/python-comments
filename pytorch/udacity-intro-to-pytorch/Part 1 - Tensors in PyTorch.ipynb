{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning.\n",
    "\n",
    "tensor = (in programmers view) multidimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(3,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[1.9287e+31, 1.7743e+28, 2.0535e-19, 2.7909e+23],\n",
      "        [6.2608e+22, 4.7428e+30, 4.4656e+30, 3.4731e-12],\n",
      "        [7.5555e+31, 1.6930e+22, 1.8465e+25, 1.9863e+08]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 4) # Do not initialize it.\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2, 3)\n",
    "\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_numbers = np.array([[1, 2],[3, 4]])\n",
    "\n",
    "print(my_numbers.shape)\n",
    "\n",
    "my_numbers = torch.tensor([[1, 2],[3, 4]])\n",
    "print(my_numbers)\n",
    "print(my_numbers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(my_numbers.dtype)\n",
    "\n",
    "t = my_numbers.to(torch.float32)\n",
    "\n",
    "print(t.dtype)\n",
    "\n",
    "print(torch.tensor([[1, 2],[3, 4]], dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "t = (torch.ones(2, 2) * 7 - 1) / 2\n",
    "print(t)\n",
    "\n",
    "print(t**2)\n",
    "\n",
    "print(torch.std(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0., -1.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "\n",
    "print(torch.cross(v2, v1)) #  the cross product of vectors\n",
    "print(torch.dot(v1,v2))    # the dot product of two 1D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute $y=\\sigma(w^Tx + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor - alias for torch.FloatTensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 5 random normal variables\n",
    "\n",
    "# features = torch.randn((1, 5)) # x = a random vector. Each of its elements is drawn from Normal distribution.\n",
    "features = torch.tensor([1,2,3,4,5], dtype = torch.float32)\n",
    "\n",
    "# True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "# and a true bias term\n",
    "bias = torch.randn((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: Calculate the output of the network with input features `features`, weights `weights`, and bias `bias`. Similar to Numpy, PyTorch has a [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum) function, as well as a `.sum()` method on tensors, for taking sums. Use the function `activation` defined above as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "y = activation(torch.sum(features * weights) + bias)\n",
    "y = activation((features * weights).sum() + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9994]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9994]])\n"
     ]
    }
   ],
   "source": [
    "y = activation(torch.dot(features, weights)+ bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way is to use matrix multiplication\n",
    "\n",
    "Use [`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) or [`torch.matmul()`](https://pytorch.org/docs/stable/torch.html#torch.matmul) for matrix multiplication.\n",
    "\n",
    "`torch.mm`: only performs *matrix* multiplication. I.e., your inputs sizes should be $n \\times m$ and $m \\times p$. Moreover, this function does not support broadcasting.<br>\n",
    "`torch.matmul`: It is more general than `torch.mm` in a way that it can be used to apply the matrix multiplication on two *tensors*. Also, it also supports broadcasting.\n",
    "\n",
    "To change the shape use:\n",
    "- `weights.reshape(a, b)`: may return a copy or a view of the original tensor.\n",
    "- `weights.resize_(a, b)`: Resizes `self` tensor (here, `weights`) to the specified size.\n",
    "- `weights.view(a, b)`: will return a new tensor with the same data as `weights` with size `(a, b)`. The returned tensor will share the underling data with the original tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.ones(2,2)\n",
    "print(test)\n",
    "print(test.view(1,4)) \n",
    "print(test) # Note that using view does not change the underlaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4., 4.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Let's change the underlying data with an in-place multiplication\n",
    "print(test.view(1,4).mul_(4))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Tip:** \n",
    "To reshape, use `view`. And, to copy a tensor, use `clone`. [here](https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch)\n",
    "\n",
    "\n",
    "> **Exercise**: Calculate the output of our little network using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9994]])\n"
     ]
    }
   ],
   "source": [
    "y = activation(torch.mm(features.view(1,5), weights.view(5,1)) + bias) # mm and view are the best options from the above.\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute $\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise:** Calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "h = activation(torch.mm(features, W1) + B1)\n",
    "output = activation(torch.mm(h, W2) + B2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy to Torch and back\n",
    "\n",
    "To create a tensor from a Numpy array, use `torch.from_numpy()`. \n",
    "\n",
    "To convert a tensor to a Numpy array, use the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91958705, 0.10415664, 0.56259259],\n",
       "       [0.78646912, 0.55737481, 0.32562772],\n",
       "       [0.42913771, 0.2366727 , 0.31890369],\n",
       "       [0.81015436, 0.97251678, 0.17452685]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9196, 0.1042, 0.5626],\n",
       "        [0.7865, 0.5574, 0.3256],\n",
       "        [0.4291, 0.2367, 0.3189],\n",
       "        [0.8102, 0.9725, 0.1745]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91958705, 0.10415664, 0.56259259],\n",
       "       [0.78646912, 0.55737481, 0.32562772],\n",
       "       [0.42913771, 0.2366727 , 0.31890369],\n",
       "       [0.81015436, 0.97251678, 0.17452685]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8392, 0.2083, 1.1252],\n",
       "        [1.5729, 1.1147, 0.6513],\n",
       "        [0.8583, 0.4733, 0.6378],\n",
       "        [1.6203, 1.9450, 0.3491]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply PyTorch Tensor by 2, in place\n",
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8391741 , 0.20831327, 1.12518519],\n",
       "       [1.57293825, 1.11474963, 0.65125543],\n",
       "       [0.85827542, 0.4733454 , 0.63780737],\n",
       "       [1.62030873, 1.94503356, 0.3490537 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array matches new values from Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5175, 0.6249, 3.3756],\n",
       "        [4.7188, 3.3442, 1.9538],\n",
       "        [2.5748, 1.4200, 1.9134],\n",
       "        [4.8609, 5.8351, 1.0472]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8392, 0.2083, 1.1252],\n",
       "        [1.5729, 1.1147, 0.6513],\n",
       "        [0.8583, 0.4733, 0.6378],\n",
       "        [1.6203, 1.9450, 0.3491]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Tensor can run on either CPU or GPU.\n",
    "\n",
    "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('We have a GPU!')\n",
    "else:\n",
    "    print('Sorry, CPU only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.6718, 0.1996],\n",
      "        [0.5633, 0.2009]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "print('Device: {}'.format(my_device))\n",
    "\n",
    "x = torch.rand(2, 2, device=my_device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_numbers = torch.tensor([[1, 2],[3, 4]])\n",
    "\n",
    "my_numbers.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_numbers_2 = torch.tensor([[1, 2],[3, 4]])\n",
    "\n",
    "my_numbers_2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.get_device_name() # torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
