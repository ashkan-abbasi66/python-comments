{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOAL: Using `nn` module to create neural networks easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define / Build Neural networks in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's design a simple MLP for classifying MNIST images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Part2_figures/example_mlp_arch_mnist.png\"></img>\n",
    "\n",
    "N(0, 1): not recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "transform = transforms.ToTensor() # PIL image [0, 255] int === ToTensor() ==> PyTorch Tensor [0, 1] float\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(root = '~/.pytorch/MNIST_data/', download=True, train=True, transform=transform) # target_transform\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a batch of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next() # next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using PyTorch Tensors, the most low-level API, for defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: torch.Size([64, 784])\n",
      "w1 shape: torch.Size([784, 256])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1) # 64, 1, 28, 28 ===> 64*784\n",
    "print(\"inputs shape:\", inputs.shape)\n",
    "\n",
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "print(\"w1 shape:\", w1.shape)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1) # sigmoid(w*x+b)\n",
    "\n",
    "out = torch.mm(h, w2) + b2  # raw scores  <=> logits\n",
    "print(out.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar computations just for one sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits for one sample from the batch:\n",
      " tensor([[ 12.0150,   3.1515,   3.1369,  -4.8155,  12.4640, -26.6047,   5.9804,\n",
      "         -12.1218,  10.9840,  -0.1860]])\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "inp = inputs[index,:].unsqueeze(0) # [784] ==> [1, 784]   # [64,1,28,28] === squeeze() ===> [64,28,28]\n",
    "\n",
    "h = activation(torch.mm(inp, w1) + b1)\n",
    "out = torch.mm(h, w2) + b2\n",
    "\n",
    "print(\"logits for one sample from the batch:\\n\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid can bring these values into the range [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9999e-01, 9.5897e-01, 9.5839e-01, 8.0377e-03, 1.0000e+00, 2.7908e-12,\n",
      "         9.9748e-01, 5.4397e-06, 9.9998e-01, 4.5364e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(activation(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, it not a proper probability distribution over the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3765)\n"
     ]
    }
   ],
   "source": [
    "print(activation(out).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of multiclass classification, we need to use softmax:\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one.\n",
    "\n",
    "The probability distribution over the classes tells us the likely class(es) the image belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4175e-01, 4.8346e-05, 4.7644e-05, 1.6761e-08, 5.3544e-01, 5.7728e-18,\n",
      "         8.1833e-04, 1.1252e-11, 1.2189e-01, 1.7175e-06]])\n",
      "torch.Size([1, 10])\n",
      "tensor([1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "print(probabilities)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(range(10)), out.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(range(10)), probabilities.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[index].numpy().squeeze(), cmap=plt.cm.gray); # images[1,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Subclassing from `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    \"\"\"\n",
    "    net = myNet()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__() # calls the constructor (__init__) of the parent class\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256) # torch.nn.Linear --- z = Wx+b \n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim = 1) # 64*784 ==> column-wise computation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x) # Note: Usually, we do not implement softmax in PyTorch directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNet(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = myNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### access to model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256])\n",
      "torch.Size([10, 256])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters:')\n",
    "\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move the model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "myNet(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "    \n",
    "print(my_device)\n",
    "\n",
    "model.to(my_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using `torch.nn.Functional` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module): # Camel Case\n",
    "    \"\"\"\n",
    "    net = myNet()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__() # calls the constructor (__init__) of the parent class\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256) # torch.nn.Linear --- z = Wx+b \n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # self.sigmoid  = nn.Sigmoid()\n",
    "        # self.softmax = nn.Softmax(dim = 1) # 64*784 ==> column-wise computation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        #x = self.sigmoid(x)\n",
    "        x = F.softmax(self.output(x))\n",
    "        #x = self.softmax(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.functional.linear(input, weight, bias) # see the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNet(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = myNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using `nn.Sequential` to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (3): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                     nn.Sigmoid(),\n",
    "                     nn.Linear(256, 10),\n",
    "                     nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=256, bias=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0] # model.hiddent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(784, 256)),\n",
    "    ('sigmoid', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(256, 10)),\n",
    "    ('softmax', nn.Softmax(dim=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=256, bias=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
