{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2280e0e4",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "How to use loss to perform backpropagation? \n",
    "\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. \n",
    "\n",
    "Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ff610",
   "metadata": {},
   "source": [
    "Let's compute:\n",
    "\n",
    "$$\n",
    "z = \\left[\\frac{1}{n}\\sum_i^n x_i^2\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70ffc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebfdda8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0606, -0.1873],\n",
      "        [ 1.7177, -1.3912]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7960a0cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1249, 0.0351],\n",
      "        [2.9506, 1.9355]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781281b",
   "metadata": {},
   "source": [
    "The autograd module keeps track of all operations and knows how to calculate the gradient for each one.\n",
    "\n",
    "Let's check it for y: (`grad_fn` shows the function that generated this variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8374319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x0000022DC917BEB8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bbb508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5115, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e711cc",
   "metadata": {},
   "source": [
    "Note: If `requires_grad` is set to False, `grad_fn` would be None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59f6ef",
   "metadata": {},
   "source": [
    "You can check the gradients for `z` but it is empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3145696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f156b5",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3383098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49e4780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 0.5303, -0.0937],\n",
      "        [ 0.8589, -0.6956]])\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2882ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5303, -0.0937],\n",
      "        [ 0.8589, -0.6956]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5802d1e",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "you cannot compute gradient of a vector with respect to another vector (Jacobian). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5531bcb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1249, 0.0351],\n",
       "        [2.9506, 1.9355]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd6c61",
   "metadata": {},
   "source": [
    "If you call `y.backward()`, you will get:\n",
    "\n",
    "```shell\n",
    "RuntimeError: grad can be implicitly created only for scalar outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9b63a",
   "metadata": {},
   "source": [
    "## Loss and Autograd together\n",
    "\n",
    "When we create a network with PyTorch, all of the parameters are initialized with `requires_grad = True`. \n",
    "\n",
    "This means that when we calculate the loss and call `loss.backward()`, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent. \n",
    "\n",
    "Below you can see an example of calculating the gradients using a backwards pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fce19",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10aa254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3815054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
    "# Run this script to enable the datasets download\n",
    "# Reference: https://github.com/pytorch/vision/issues/1938\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a9f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b564a",
   "metadata": {},
   "source": [
    "### build a model and compute loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c4b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "scores = model(images)\n",
    "loss = criterion(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2868eb7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0044,  0.0044,  0.0044,  ...,  0.0044,  0.0044,  0.0044],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f5f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
