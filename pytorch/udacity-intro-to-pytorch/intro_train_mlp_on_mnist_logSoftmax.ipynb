{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45653d1",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "سلام دوستان\n",
    "\n",
    "در کلاس تلاش کردیم از Tensorboard برای ترسیم نمودار خطای آموزش استفاده کنیم. متاسفانه جواب نداد. من موضوع را بررسی کردم. بطور کلی در پایتورچ به دو روش می توانید از tensorboard استفاده کنید. یکی بسته TensorboardX و دیگری ماژول torch.utils.tensorboard. دومی درون پایتورچ از نسخه 1.4 به بعد قرارداده شده است و در \n",
    "حقیقت مبتنی بر همان بسته ی Tensorboard که در Tensorflow است کار می کند.\n",
    "\n",
    "پایتورچی که روی سیستم من بود نسخه 1.1 بود و خیلی قدیمی بود و احتمالا به همین دلیل TensorboardX کار نکرد. اگر به لینک TensorboardX در \n",
    "https://github.com/lanpa/tensorboardX\n",
    "مراجعه کنید میبینید که بسته را روی پایتورچ 1.8 امتحان کرده‌اند.\n",
    "\n",
    "نهایتا من سیستم خودم را بروز رسانی کردم و اینبار از ماژول torch.utils.tensorboard استفاده کردم.\n",
    "اگر روی سیستم شما این ماژول کار نکرد از دستور \n",
    "pip install tensorboard\n",
    "استفاده کنید برای نصب tensorboard\n",
    "همانطور که گفتم این همان تنسوربورد موجود در Tensorflow است که پایتورچ از نسخه 1.4 به بعد می‌تواند آنرا استفاده کند.\n",
    "\n",
    "برای اطلاعات بیشتر به این لینک مراجعه کنید\n",
    "https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c877835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter(log_dir='./TensorboardX_logs/') \n",
    "\n",
    "\n",
    "# ====================================================\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# For each run, we want to create a separate folder to store Tensorboard's content\n",
    "# In this way, we can easily switch between them in Tensorboard's GUI.\n",
    "log_folder_name = 'logs/experiment-at-%s'%datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(log_dir = log_folder_name)\n",
    "# ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bcbd2b",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b55ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "#transform = transforms.ToTensor() # PIL image [0, 255] int === ToTensor() ==> PyTorch Tensor [0, 1] float\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(root = '~/.pytorch/MNIST_data/', download=True, train=True, transform=transform) # target_transform\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82753964",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f43e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1)).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2e881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff8b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss() # Negative log-likehood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec5143",
   "metadata": {},
   "source": [
    "$w_{new} = w_{old} - \\eta*\\text{Grad}_{w}(\\text{one sample}, \\text{criterion})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407f8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cc698",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29938ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 2.251042738398001\n",
      "Training loss = 1.9874214423236563\n",
      "Training loss = 1.33196158087584\n",
      "Training loss = 0.8309394008061016\n",
      "Training loss = 0.6249460220845269\n"
     ]
    }
   ],
   "source": [
    "my_device = 'cuda'\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten - N*C*H*W ===> N*(C*H*W) <=> 64*784\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward computation\n",
    "        output = model(images.to(my_device))\n",
    "        \n",
    "        loss = criterion(output, labels.to(my_device))\n",
    "        \n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        current_loss = running_loss/len(trainloader)\n",
    "        print(f\"Training loss = {current_loss}\")\n",
    "        # ====================================================\n",
    "        writer.add_scalar('trainloss', current_loss,epoch)\n",
    "        # ====================================================\n",
    "\n",
    "# ====================================================\n",
    "# It is good to run one of the following two commands:\n",
    "# writer.flush() # to make sure that all pending events have been written to disk.\n",
    "writer.close()   # If you do not need the summary writer anymore, call close() method.\n",
    "# ====================================================\n",
    "\n",
    "# To run tensorboard, open your command line\n",
    "# Change your directory to where that this directory (Tensorboard_logs) can be accessed with the following command\n",
    "# Run this on your command line\n",
    "# tensorboard --logdir=Tensorboard_logs\n",
    "# Goto the address given by tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f270e76",
   "metadata": {},
   "source": [
    "After training, when you run the tensorboard, you should observe something similar to the following figure\n",
    "\n",
    "<img src='tensorboard_example_screenshot.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c5540",
   "metadata": {},
   "source": [
    "# Prediction / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ed2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47db033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.5409, -9.2886, -4.3122, -7.2183, -0.2336, -6.1455, -5.8437, -3.9721,\n",
      "         -4.2623, -1.8606]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "images[data_index].shape  # torch.Size([1, 28, 28])\n",
    "\n",
    "input_vector = images[data_index].view(1, 784)\n",
    "\n",
    "# Turn off gradient computation\n",
    "with torch.no_grad():\n",
    "    scores = model(input_vector.to(my_device))\n",
    "\n",
    "print(scores) # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85409d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.3091e-04, 9.2474e-05, 1.3404e-02, 7.3304e-04, 7.9170e-01, 2.1432e-03,\n",
      "         2.8982e-03, 1.8833e-02, 1.4091e-02, 1.5558e-01]], device='cuda:0')\n",
      "tensor([[5.3091e-04, 9.2474e-05, 1.3404e-02, 7.3304e-04, 7.9170e-01, 2.1432e-03,\n",
      "         2.8982e-03, 1.8833e-02, 1.4091e-02, 1.5558e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashkan\\AppData\\Local\\Temp\\ipykernel_6720\\1124326387.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(F.softmax(scores))\n"
     ]
    }
   ],
   "source": [
    "print(nn.Softmax(dim=1)(scores))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "print(F.softmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "920609b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(nn.Softmax(dim=1)(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "510bce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[0.7917]], device='cuda:0'),\n",
      "indices=tensor([[4]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(torch.topk(nn.Softmax(dim=1)(scores), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fa3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 0, 5, 4, 5, 6, 7, 6, 7, 7, 7, 8, 1, 5, 5, 0, 3, 1, 5, 4, 0, 6, 0,\n",
       "        3, 7, 6, 5, 3, 2, 2, 1, 1, 4, 0, 9, 5, 4, 6, 6, 3, 8, 1, 5, 0, 4, 3, 9,\n",
       "        4, 5, 4, 0, 5, 6, 7, 5, 4, 3, 4, 9, 6, 0, 4, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544a208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9064a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
